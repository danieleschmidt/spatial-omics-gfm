"""
Production Deployment Orchestrator
Complete production deployment system with monitoring and auto-scaling
"""
import asyncio
import json
import logging
import os
import time
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union

import yaml


class DeploymentEnvironment(Enum):
    """Deployment environment types"""
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION = "production"
    CANARY = "canary"


class ServiceStatus(Enum):
    """Service deployment status"""
    PENDING = "pending"
    DEPLOYING = "deploying"
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    FAILED = "failed"


@dataclass
class ServiceConfig:
    """Configuration for a deployable service"""
    name: str
    image: str
    version: str
    port: int
    replicas: int
    environment: DeploymentEnvironment
    resources: Dict[str, str]
    health_check: Dict[str, Any]
    dependencies: List[str] = field(default_factory=list)
    env_vars: Dict[str, str] = field(default_factory=dict)


@dataclass
class DeploymentResult:
    """Result of deployment operation"""
    service_name: str
    environment: DeploymentEnvironment
    status: ServiceStatus
    deployment_time: float
    endpoints: List[str]
    metrics: Dict[str, Any]
    logs: List[str] = field(default_factory=list)
    error_message: Optional[str] = None


class ProductionOrchestrator:
    """
    Production Deployment Orchestrator
    
    Manages complete production deployment lifecycle:
    - Multi-environment deployment (dev/staging/prod)
    - Container orchestration with Kubernetes
    - Blue-green and canary deployments
    - Auto-scaling and load balancing
    - Health monitoring and alerting
    - Rollback capabilities
    """
    
    def __init__(self, config_path: Optional[Path] = None):
        self.config_path = config_path or Path("deployment/config.yaml")
        self.config = self._load_deployment_config()
        self.logger = self._setup_logging()
        
        # Deployment state
        self.services: Dict[str, ServiceConfig] = {}
        self.deployments: Dict[str, DeploymentResult] = {}
        
        # Infrastructure components
        self.container_registry = ContainerRegistry(self.config["registry"])
        self.kubernetes_manager = KubernetesManager(self.config["kubernetes"])
        self.monitoring_system = ProductionMonitoring(self.config["monitoring"])
        self.load_balancer = LoadBalancerManager(self.config["load_balancer"])
        
        self._initialize_orchestrator()
    
    def _load_deployment_config(self) -> Dict[str, Any]:
        """Load deployment configuration"""
        if self.config_path.exists():
            with open(self.config_path, 'r') as f:
                return yaml.safe_load(f)
        
        # Default configuration
        return {
            "registry": {
                "type": "docker_hub",
                "repository": "spatial-omics-gfm",
                "auth": {
                    "username": "${DOCKER_USERNAME}",
                    "password": "${DOCKER_PASSWORD}"
                }
            },
            "kubernetes": {
                "cluster_name": "spatial-omics-cluster",
                "namespace": "spatial-omics",
                "config_path": "~/.kube/config"
            },
            "monitoring": {
                "prometheus_url": "http://prometheus:9090",
                "grafana_url": "http://grafana:3000",
                "alert_manager_url": "http://alertmanager:9093"
            },
            "load_balancer": {
                "type": "nginx",
                "ssl_enabled": True,
                "cert_manager": True
            },
            "environments": {
                "development": {
                    "replicas": 1,
                    "resources": {
                        "cpu": "100m",
                        "memory": "256Mi"
                    }
                },
                "staging": {
                    "replicas": 2,
                    "resources": {
                        "cpu": "500m",
                        "memory": "1Gi"
                    }
                },
                "production": {
                    "replicas": 3,
                    "resources": {
                        "cpu": "1000m",
                        "memory": "2Gi"
                    }
                }
            }
        }
    
    def _setup_logging(self) -> logging.Logger:
        """Setup structured logging for orchestrator"""
        logger = logging.getLogger("production_orchestrator")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - [%(deployment_env)s] %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            
        return logger
    
    def _initialize_orchestrator(self) -> None:
        """Initialize production orchestrator"""
        self.logger.info("ðŸš€ Initializing Production Deployment Orchestrator")
        
        # Load service configurations
        self._load_service_configs()
        
        # Initialize infrastructure components
        self._initialize_infrastructure()
        
        self.logger.info("âœ… Production Orchestrator initialized")
    
    def _load_service_configs(self) -> None:
        """Load service configurations"""
        # Define core services
        services = [
            ServiceConfig(
                name="spatial-gfm-api",
                image="spatial-omics-gfm/api",
                version="latest",
                port=8000,
                replicas=3,
                environment=DeploymentEnvironment.PRODUCTION,
                resources={"cpu": "1000m", "memory": "2Gi"},
                health_check={
                    "path": "/health",
                    "port": 8000,
                    "interval": 30,
                    "timeout": 5,
                    "retries": 3
                },
                env_vars={
                    "LOG_LEVEL": "INFO",
                    "ENVIRONMENT": "production"
                }
            ),
            ServiceConfig(
                name="spatial-gfm-worker",
                image="spatial-omics-gfm/worker",
                version="latest",
                port=8001,
                replicas=5,
                environment=DeploymentEnvironment.PRODUCTION,
                resources={"cpu": "2000m", "memory": "4Gi"},
                health_check={
                    "path": "/health",
                    "port": 8001,
                    "interval": 30,
                    "timeout": 10,
                    "retries": 3
                },
                dependencies=["spatial-gfm-api"],
                env_vars={
                    "WORKER_CONCURRENCY": "4",
                    "QUEUE_BACKEND": "redis"
                }
            ),
            ServiceConfig(
                name="spatial-gfm-ui",
                image="spatial-omics-gfm/ui",
                version="latest",
                port=3000,
                replicas=2,
                environment=DeploymentEnvironment.PRODUCTION,
                resources={"cpu": "500m", "memory": "1Gi"},
                health_check={
                    "path": "/",
                    "port": 3000,
                    "interval": 30,
                    "timeout": 5,
                    "retries": 2
                },
                dependencies=["spatial-gfm-api"]
            )
        ]
        
        for service in services:
            self.services[service.name] = service
        
        self.logger.info(f"ðŸ“‹ Loaded {len(self.services)} service configurations")
    
    def _initialize_infrastructure(self) -> None:
        """Initialize infrastructure components"""
        # Initialize container registry
        self.container_registry.initialize()
        
        # Initialize Kubernetes manager
        self.kubernetes_manager.initialize()
        
        # Initialize monitoring
        self.monitoring_system.initialize()
        
        # Initialize load balancer
        self.load_balancer.initialize()
    
    async def deploy_service(
        self,
        service_name: str,
        environment: DeploymentEnvironment,
        strategy: str = "rolling_update"
    ) -> DeploymentResult:
        """
        Deploy a specific service to target environment
        
        Args:
            service_name: Name of service to deploy
            environment: Target deployment environment
            strategy: Deployment strategy (rolling_update, blue_green, canary)
            
        Returns:
            DeploymentResult with deployment status and metrics
        """
        if service_name not in self.services:
            raise ValueError(f"Service {service_name} not found")
        
        service_config = self.services[service_name]
        deployment_start = time.time()
        
        self.logger.info(f"ðŸš€ Deploying {service_name} to {environment.value} using {strategy}")
        
        try:
            # Build and push container image
            image_tag = await self._build_and_push_image(service_config, environment)
            
            # Deploy dependencies first
            await self._deploy_dependencies(service_config, environment)
            
            # Execute deployment strategy
            if strategy == "rolling_update":
                deployment_result = await self._rolling_update_deployment(
                    service_config, environment, image_tag
                )
            elif strategy == "blue_green":
                deployment_result = await self._blue_green_deployment(
                    service_config, environment, image_tag
                )
            elif strategy == "canary":
                deployment_result = await self._canary_deployment(
                    service_config, environment, image_tag
                )
            else:
                raise ValueError(f"Unknown deployment strategy: {strategy}")
            
            # Configure monitoring and alerting
            await self._setup_service_monitoring(service_config, environment)
            
            # Configure load balancing
            await self._configure_load_balancing(service_config, environment)
            
            # Verify deployment health
            health_status = await self._verify_deployment_health(service_config, environment)
            
            deployment_result.status = ServiceStatus.HEALTHY if health_status else ServiceStatus.DEGRADED
            deployment_result.deployment_time = time.time() - deployment_start
            
            # Store deployment result
            self.deployments[f"{service_name}_{environment.value}"] = deployment_result
            
            self.logger.info(f"âœ… Successfully deployed {service_name} to {environment.value}")
            
            return deployment_result
            
        except Exception as e:
            error_result = DeploymentResult(
                service_name=service_name,
                environment=environment,
                status=ServiceStatus.FAILED,
                deployment_time=time.time() - deployment_start,
                endpoints=[],
                metrics={},
                error_message=str(e)
            )
            
            self.logger.error(f"âŒ Failed to deploy {service_name}: {e}")
            
            # Attempt rollback
            await self._rollback_deployment(service_name, environment)
            
            return error_result
    
    async def _build_and_push_image(
        self,
        service_config: ServiceConfig,
        environment: DeploymentEnvironment
    ) -> str:
        """Build and push container image"""
        image_tag = f"{service_config.image}:{service_config.version}-{environment.value}"
        
        self.logger.info(f"ðŸ”¨ Building image {image_tag}")
        
        # Build image
        build_success = await self.container_registry.build_image(
            service_config.name,
            image_tag,
            environment
        )
        
        if not build_success:
            raise Exception(f"Failed to build image {image_tag}")
        
        # Push to registry
        push_success = await self.container_registry.push_image(image_tag)
        
        if not push_success:
            raise Exception(f"Failed to push image {image_tag}")
        
        return image_tag
    
    async def _deploy_dependencies(
        self,
        service_config: ServiceConfig,
        environment: DeploymentEnvironment
    ) -> None:
        """Deploy service dependencies"""
        for dependency in service_config.dependencies:
            if dependency in self.services:
                self.logger.info(f"ðŸ“¦ Deploying dependency: {dependency}")
                
                # Check if dependency is already deployed
                deployment_key = f"{dependency}_{environment.value}"
                if deployment_key not in self.deployments:
                    await self.deploy_service(dependency, environment)
                else:
                    # Verify dependency is healthy
                    dep_result = self.deployments[deployment_key]
                    if dep_result.status != ServiceStatus.HEALTHY:
                        await self.deploy_service(dependency, environment)
    
    async def _rolling_update_deployment(
        self,
        service_config: ServiceConfig,
        environment: DeploymentEnvironment,
        image_tag: str
    ) -> DeploymentResult:
        """Execute rolling update deployment strategy"""
        self.logger.info(f"ðŸ”„ Executing rolling update for {service_config.name}")
        
        # Deploy to Kubernetes
        deployment_success = await self.kubernetes_manager.deploy_service(
            service_config,
            environment,
            image_tag,
            strategy="RollingUpdate"
        )
        
        if not deployment_success:
            raise Exception("Kubernetes deployment failed")
        
        # Wait for rollout completion
        rollout_success = await self.kubernetes_manager.wait_for_rollout(
            service_config.name,
            environment,
            timeout=600  # 10 minutes
        )
        
        if not rollout_success:
            raise Exception("Rollout failed or timed out")
        
        # Get service endpoints
        endpoints = await self.kubernetes_manager.get_service_endpoints(
            service_config.name,
            environment
        )
        
        return DeploymentResult(
            service_name=service_config.name,
            environment=environment,
            status=ServiceStatus.HEALTHY,
            deployment_time=0.0,  # Will be set by caller
            endpoints=endpoints,
            metrics={"strategy": "rolling_update"}
        )
    
    async def _blue_green_deployment(
        self,
        service_config: ServiceConfig,
        environment: DeploymentEnvironment,
        image_tag: str
    ) -> DeploymentResult:
        """Execute blue-green deployment strategy"""
        self.logger.info(f"ðŸ”µðŸŸ¢ Executing blue-green deployment for {service_config.name}")
        
        # Deploy green environment
        green_deployment = await self.kubernetes_manager.deploy_service(
            service_config,
            environment,
            image_tag,
            strategy="BlueGreen",
            color="green"
        )
        
        if not green_deployment:
            raise Exception("Green deployment failed")
        
        # Wait for green to be healthy
        green_healthy = await self._verify_deployment_health(service_config, environment, "green")
        
        if not green_healthy:
            raise Exception("Green deployment health check failed")
        
        # Switch traffic to green
        switch_success = await self.load_balancer.switch_traffic(
            service_config.name,
            environment,
            "green"
        )
        
        if not switch_success:
            raise Exception("Traffic switch to green failed")
        
        # Clean up blue environment after successful switch
        await self.kubernetes_manager.cleanup_blue_environment(service_config.name, environment)
        
        endpoints = await self.kubernetes_manager.get_service_endpoints(
            service_config.name,
            environment
        )
        
        return DeploymentResult(
            service_name=service_config.name,
            environment=environment,
            status=ServiceStatus.HEALTHY,
            deployment_time=0.0,
            endpoints=endpoints,
            metrics={"strategy": "blue_green", "active_color": "green"}
        )
    
    async def _canary_deployment(
        self,
        service_config: ServiceConfig,
        environment: DeploymentEnvironment,
        image_tag: str
    ) -> DeploymentResult:
        """Execute canary deployment strategy"""
        self.logger.info(f"ðŸ¤ Executing canary deployment for {service_config.name}")
        
        # Deploy canary with reduced traffic (10%)
        canary_deployment = await self.kubernetes_manager.deploy_service(
            service_config,
            environment,
            image_tag,
            strategy="Canary",
            traffic_split={"canary": 10, "stable": 90}
        )
        
        if not canary_deployment:
            raise Exception("Canary deployment failed")
        
        # Monitor canary performance
        canary_metrics = await self._monitor_canary_performance(
            service_config,
            environment,
            duration=300  # 5 minutes
        )
        
        # Decide whether to promote canary
        promote_canary = self._should_promote_canary(canary_metrics)
        
        if promote_canary:
            # Gradually increase canary traffic
            traffic_splits = [
                {"canary": 25, "stable": 75},
                {"canary": 50, "stable": 50},
                {"canary": 100, "stable": 0}
            ]
            
            for split in traffic_splits:
                await self.load_balancer.update_traffic_split(
                    service_config.name,
                    environment,
                    split
                )
                
                # Monitor for 2 minutes at each stage
                await asyncio.sleep(120)
                
                stage_metrics = await self._monitor_canary_performance(
                    service_config,
                    environment,
                    duration=60
                )
                
                if not self._should_promote_canary(stage_metrics):
                    # Rollback to stable
                    await self._rollback_canary(service_config, environment)
                    raise Exception("Canary performance degraded, rolled back")
            
            # Promote canary to stable
            await self.kubernetes_manager.promote_canary_to_stable(
                service_config.name,
                environment
            )
            
        else:
            # Rollback canary
            await self._rollback_canary(service_config, environment)
            raise Exception("Canary metrics did not meet promotion criteria")
        
        endpoints = await self.kubernetes_manager.get_service_endpoints(
            service_config.name,
            environment
        )
        
        return DeploymentResult(
            service_name=service_config.name,
            environment=environment,
            status=ServiceStatus.HEALTHY,
            deployment_time=0.0,
            endpoints=endpoints,
            metrics={"strategy": "canary", "promoted": promote_canary}
        )
    
    async def _setup_service_monitoring(
        self,
        service_config: ServiceConfig,
        environment: DeploymentEnvironment
    ) -> None:
        """Setup monitoring and alerting for service"""
        self.logger.info(f"ðŸ“Š Setting up monitoring for {service_config.name}")
        
        # Configure Prometheus scraping
        await self.monitoring_system.configure_prometheus_scraping(
            service_config,
            environment
        )
        
        # Setup Grafana dashboard
        await self.monitoring_system.create_grafana_dashboard(
            service_config,
            environment
        )
        
        # Configure alerts
        alerts = [
            {
                "name": f"{service_config.name}-high-error-rate",
                "condition": f"rate(http_requests_total{{job=\"{service_config.name}\",status=~\"5..\"})[5m]) > 0.05",
                "severity": "critical"
            },
            {
                "name": f"{service_config.name}-high-latency",
                "condition": f"histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{{job=\"{service_config.name}\"}}[5m])) > 2",
                "severity": "warning"
            },
            {
                "name": f"{service_config.name}-low-availability",
                "condition": f"up{{job=\"{service_config.name}\"}} < 0.9",
                "severity": "critical"
            }
        ]
        
        for alert in alerts:
            await self.monitoring_system.create_alert_rule(alert)
    
    async def _configure_load_balancing(
        self,
        service_config: ServiceConfig,
        environment: DeploymentEnvironment
    ) -> None:
        """Configure load balancing for service"""
        self.logger.info(f"âš–ï¸  Configuring load balancing for {service_config.name}")
        
        # Configure ingress
        ingress_config = {
            "service_name": service_config.name,
            "port": service_config.port,
            "health_check": service_config.health_check,
            "ssl_enabled": True,
            "rate_limiting": {
                "requests_per_minute": 1000,
                "burst": 50
            }
        }
        
        await self.load_balancer.configure_ingress(
            service_config.name,
            environment,
            ingress_config
        )
    
    async def _verify_deployment_health(
        self,
        service_config: ServiceConfig,
        environment: DeploymentEnvironment,
        color: Optional[str] = None
    ) -> bool:
        """Verify deployment health"""
        self.logger.info(f"ðŸ¥ Verifying health for {service_config.name}")
        
        # Check Kubernetes pod health
        pods_healthy = await self.kubernetes_manager.check_pod_health(
            service_config.name,
            environment,
            color
        )
        
        if not pods_healthy:
            return False
        
        # Check service endpoint health
        endpoints = await self.kubernetes_manager.get_service_endpoints(
            service_config.name,
            environment
        )
        
        for endpoint in endpoints:
            health_url = f"{endpoint}{service_config.health_check['path']}"
            
            # Simulate health check
            # In production, would make actual HTTP request
            await asyncio.sleep(0.1)
        
        return True
    
    async def _monitor_canary_performance(
        self,
        service_config: ServiceConfig,
        environment: DeploymentEnvironment,
        duration: int
    ) -> Dict[str, float]:
        """Monitor canary deployment performance"""
        self.logger.info(f"ðŸ“ˆ Monitoring canary performance for {duration}s")
        
        # Collect metrics over specified duration
        start_time = time.time()
        metrics = {
            "error_rate": 0.0,
            "avg_latency": 0.0,
            "throughput": 0.0,
            "cpu_usage": 0.0,
            "memory_usage": 0.0
        }
        
        # Simulate metric collection
        await asyncio.sleep(min(duration, 5))  # Cap at 5s for testing
        
        # Generate realistic canary metrics
        import random
        metrics["error_rate"] = random.uniform(0.001, 0.01)  # 0.1% - 1%
        metrics["avg_latency"] = random.uniform(50, 200)     # 50-200ms
        metrics["throughput"] = random.uniform(100, 500)     # 100-500 RPS
        metrics["cpu_usage"] = random.uniform(20, 80)        # 20-80%
        metrics["memory_usage"] = random.uniform(30, 70)     # 30-70%
        
        return metrics
    
    def _should_promote_canary(self, metrics: Dict[str, float]) -> bool:
        """Determine if canary should be promoted based on metrics"""
        promotion_criteria = {
            "max_error_rate": 0.05,      # 5%
            "max_avg_latency": 500,      # 500ms
            "min_throughput": 50,        # 50 RPS
            "max_cpu_usage": 90,         # 90%
            "max_memory_usage": 85       # 85%
        }
        
        checks = [
            metrics["error_rate"] <= promotion_criteria["max_error_rate"],
            metrics["avg_latency"] <= promotion_criteria["max_avg_latency"],
            metrics["throughput"] >= promotion_criteria["min_throughput"],
            metrics["cpu_usage"] <= promotion_criteria["max_cpu_usage"],
            metrics["memory_usage"] <= promotion_criteria["max_memory_usage"]
        ]
        
        return all(checks)
    
    async def _rollback_canary(
        self,
        service_config: ServiceConfig,
        environment: DeploymentEnvironment
    ) -> None:
        """Rollback canary deployment"""
        self.logger.warning(f"ðŸ”™ Rolling back canary for {service_config.name}")
        
        # Restore traffic to stable version
        await self.load_balancer.update_traffic_split(
            service_config.name,
            environment,
            {"canary": 0, "stable": 100}
        )
        
        # Remove canary deployment
        await self.kubernetes_manager.remove_canary_deployment(
            service_config.name,
            environment
        )
    
    async def _rollback_deployment(
        self,
        service_name: str,
        environment: DeploymentEnvironment
    ) -> None:
        """Rollback failed deployment"""
        self.logger.warning(f"ðŸ”™ Rolling back deployment for {service_name}")
        
        # Get previous deployment
        previous_deployment = await self.kubernetes_manager.get_previous_deployment(
            service_name,
            environment
        )
        
        if previous_deployment:
            # Rollback to previous version
            await self.kubernetes_manager.rollback_deployment(
                service_name,
                environment,
                previous_deployment
            )
        else:
            self.logger.error(f"No previous deployment found for {service_name}")
    
    async def deploy_all_services(
        self,
        environment: DeploymentEnvironment,
        strategy: str = "rolling_update"
    ) -> Dict[str, DeploymentResult]:
        """Deploy all services to target environment"""
        self.logger.info(f"ðŸš€ Deploying all services to {environment.value}")
        
        results = {}
        
        # Determine deployment order based on dependencies
        deployment_order = self._calculate_deployment_order()
        
        for service_name in deployment_order:
            try:
                result = await self.deploy_service(service_name, environment, strategy)
                results[service_name] = result
                
                if result.status == ServiceStatus.FAILED:
                    self.logger.error(f"âŒ Service {service_name} deployment failed")
                    # Continue with other services
                
            except Exception as e:
                self.logger.error(f"âŒ Exception deploying {service_name}: {e}")
                results[service_name] = DeploymentResult(
                    service_name=service_name,
                    environment=environment,
                    status=ServiceStatus.FAILED,
                    deployment_time=0.0,
                    endpoints=[],
                    metrics={},
                    error_message=str(e)
                )
        
        # Generate deployment summary
        successful = len([r for r in results.values() if r.status == ServiceStatus.HEALTHY])
        total = len(results)
        
        self.logger.info(f"ðŸ“Š Deployment summary: {successful}/{total} services deployed successfully")
        
        return results
    
    def _calculate_deployment_order(self) -> List[str]:
        """Calculate optimal deployment order based on dependencies"""
        ordered_services = []
        remaining_services = set(self.services.keys())
        
        while remaining_services:
            # Find services with no undeployed dependencies
            ready_services = []
            
            for service_name in remaining_services:
                service = self.services[service_name]
                
                # Check if all dependencies are already deployed
                deps_satisfied = all(
                    dep in ordered_services or dep not in self.services
                    for dep in service.dependencies
                )
                
                if deps_satisfied:
                    ready_services.append(service_name)
            
            if not ready_services:
                # Circular dependency or missing dependency
                ready_services = list(remaining_services)
            
            # Add ready services to deployment order
            for service_name in sorted(ready_services):  # Sort for deterministic order
                ordered_services.append(service_name)
                remaining_services.remove(service_name)
        
        return ordered_services
    
    async def scale_service(
        self,
        service_name: str,
        environment: DeploymentEnvironment,
        replicas: int
    ) -> bool:
        """Scale service to specified number of replicas"""
        if service_name not in self.services:
            raise ValueError(f"Service {service_name} not found")
        
        self.logger.info(f"ðŸ“ˆ Scaling {service_name} to {replicas} replicas")
        
        success = await self.kubernetes_manager.scale_deployment(
            service_name,
            environment,
            replicas
        )
        
        if success:
            # Update service config
            self.services[service_name].replicas = replicas
            
            # Wait for scaling to complete
            await self.kubernetes_manager.wait_for_scale_completion(
                service_name,
                environment,
                replicas
            )
        
        return success
    
    def get_deployment_status(self) -> Dict[str, Any]:
        """Get current deployment status across all environments"""
        status = {
            "services": {},
            "environments": {},
            "overall_health": "healthy"
        }
        
        # Collect service status
        for service_name, service_config in self.services.items():
            status["services"][service_name] = {
                "image": service_config.image,
                "version": service_config.version,
                "replicas": service_config.replicas,
                "environments": {}
            }
            
            # Check deployment status in each environment
            for env in DeploymentEnvironment:
                deployment_key = f"{service_name}_{env.value}"
                if deployment_key in self.deployments:
                    deployment = self.deployments[deployment_key]
                    status["services"][service_name]["environments"][env.value] = {
                        "status": deployment.status.value,
                        "endpoints": deployment.endpoints,
                        "deployment_time": deployment.deployment_time
                    }
        
        # Collect environment status
        for env in DeploymentEnvironment:
            env_deployments = [
                d for d in self.deployments.values()
                if d.environment == env
            ]
            
            if env_deployments:
                healthy_count = len([d for d in env_deployments if d.status == ServiceStatus.HEALTHY])
                total_count = len(env_deployments)
                
                status["environments"][env.value] = {
                    "total_services": total_count,
                    "healthy_services": healthy_count,
                    "health_percentage": (healthy_count / total_count) * 100 if total_count > 0 else 0
                }
        
        # Determine overall health
        all_deployments = list(self.deployments.values())
        if all_deployments:
            unhealthy_count = len([d for d in all_deployments if d.status in [ServiceStatus.FAILED, ServiceStatus.UNHEALTHY]])
            
            if unhealthy_count > 0:
                status["overall_health"] = "degraded" if unhealthy_count < len(all_deployments) / 2 else "unhealthy"
        
        return status


class ContainerRegistry:
    """Container registry management"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger("container_registry")
    
    def initialize(self) -> None:
        """Initialize container registry"""
        self.logger.info("ðŸ³ Initializing Container Registry")
    
    async def build_image(
        self,
        service_name: str,
        image_tag: str,
        environment: DeploymentEnvironment
    ) -> bool:
        """Build container image"""
        self.logger.info(f"ðŸ”¨ Building image {image_tag}")
        
        # Simulate image build
        await asyncio.sleep(1.0)
        
        return True
    
    async def push_image(self, image_tag: str) -> bool:
        """Push image to registry"""
        self.logger.info(f"ðŸ“¤ Pushing image {image_tag}")
        
        # Simulate image push
        await asyncio.sleep(0.5)
        
        return True


class KubernetesManager:
    """Kubernetes cluster management"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger("kubernetes_manager")
    
    def initialize(self) -> None:
        """Initialize Kubernetes manager"""
        self.logger.info("â˜¸ï¸  Initializing Kubernetes Manager")
    
    async def deploy_service(
        self,
        service_config: ServiceConfig,
        environment: DeploymentEnvironment,
        image_tag: str,
        strategy: str = "RollingUpdate",
        **kwargs
    ) -> bool:
        """Deploy service to Kubernetes"""
        self.logger.info(f"â˜¸ï¸  Deploying {service_config.name} with strategy {strategy}")
        
        # Simulate Kubernetes deployment
        await asyncio.sleep(2.0)
        
        return True
    
    async def wait_for_rollout(
        self,
        service_name: str,
        environment: DeploymentEnvironment,
        timeout: int = 600
    ) -> bool:
        """Wait for deployment rollout to complete"""
        self.logger.info(f"â³ Waiting for rollout of {service_name}")
        
        # Simulate rollout wait
        await asyncio.sleep(1.0)
        
        return True
    
    async def get_service_endpoints(
        self,
        service_name: str,
        environment: DeploymentEnvironment
    ) -> List[str]:
        """Get service endpoints"""
        # Simulate endpoint discovery
        return [f"http://{service_name}.{environment.value}.svc.cluster.local"]
    
    async def check_pod_health(
        self,
        service_name: str,
        environment: DeploymentEnvironment,
        color: Optional[str] = None
    ) -> bool:
        """Check pod health status"""
        # Simulate health check
        await asyncio.sleep(0.2)
        return True
    
    async def scale_deployment(
        self,
        service_name: str,
        environment: DeploymentEnvironment,
        replicas: int
    ) -> bool:
        """Scale deployment"""
        self.logger.info(f"ðŸ“ˆ Scaling {service_name} to {replicas} replicas")
        
        # Simulate scaling
        await asyncio.sleep(1.0)
        
        return True
    
    async def wait_for_scale_completion(
        self,
        service_name: str,
        environment: DeploymentEnvironment,
        target_replicas: int
    ) -> bool:
        """Wait for scaling to complete"""
        await asyncio.sleep(0.5)
        return True
    
    async def cleanup_blue_environment(
        self,
        service_name: str,
        environment: DeploymentEnvironment
    ) -> None:
        """Cleanup blue environment after blue-green deployment"""
        await asyncio.sleep(0.5)
    
    async def promote_canary_to_stable(
        self,
        service_name: str,
        environment: DeploymentEnvironment
    ) -> None:
        """Promote canary deployment to stable"""
        await asyncio.sleep(0.5)
    
    async def remove_canary_deployment(
        self,
        service_name: str,
        environment: DeploymentEnvironment
    ) -> None:
        """Remove canary deployment"""
        await asyncio.sleep(0.3)
    
    async def get_previous_deployment(
        self,
        service_name: str,
        environment: DeploymentEnvironment
    ) -> Optional[str]:
        """Get previous deployment version"""
        return "previous-version-123"
    
    async def rollback_deployment(
        self,
        service_name: str,
        environment: DeploymentEnvironment,
        previous_deployment: str
    ) -> None:
        """Rollback to previous deployment"""
        await asyncio.sleep(1.0)


class ProductionMonitoring:
    """Production monitoring and alerting"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger("production_monitoring")
    
    def initialize(self) -> None:
        """Initialize monitoring system"""
        self.logger.info("ðŸ“Š Initializing Production Monitoring")
    
    async def configure_prometheus_scraping(
        self,
        service_config: ServiceConfig,
        environment: DeploymentEnvironment
    ) -> None:
        """Configure Prometheus scraping for service"""
        await asyncio.sleep(0.2)
    
    async def create_grafana_dashboard(
        self,
        service_config: ServiceConfig,
        environment: DeploymentEnvironment
    ) -> None:
        """Create Grafana dashboard for service"""
        await asyncio.sleep(0.3)
    
    async def create_alert_rule(self, alert_config: Dict[str, Any]) -> None:
        """Create alert rule"""
        await asyncio.sleep(0.1)


class LoadBalancerManager:
    """Load balancer and ingress management"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger("load_balancer_manager")
    
    def initialize(self) -> None:
        """Initialize load balancer"""
        self.logger.info("âš–ï¸  Initializing Load Balancer Manager")
    
    async def configure_ingress(
        self,
        service_name: str,
        environment: DeploymentEnvironment,
        ingress_config: Dict[str, Any]
    ) -> None:
        """Configure ingress for service"""
        await asyncio.sleep(0.3)
    
    async def switch_traffic(
        self,
        service_name: str,
        environment: DeploymentEnvironment,
        target_color: str
    ) -> bool:
        """Switch traffic to target deployment"""
        await asyncio.sleep(0.5)
        return True
    
    async def update_traffic_split(
        self,
        service_name: str,
        environment: DeploymentEnvironment,
        traffic_split: Dict[str, int]
    ) -> None:
        """Update traffic split percentages"""
        await asyncio.sleep(0.2)


# CLI interface for production orchestrator
async def main():
    """Main entry point for production orchestrator"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Production Deployment Orchestrator")
    parser.add_argument("--config", type=Path, help="Configuration file path")
    parser.add_argument("--environment", type=str, choices=["development", "staging", "production"], 
                       default="production", help="Target environment")
    parser.add_argument("--service", type=str, help="Specific service to deploy")
    parser.add_argument("--strategy", type=str, choices=["rolling_update", "blue_green", "canary"],
                       default="rolling_update", help="Deployment strategy")
    parser.add_argument("--action", type=str, choices=["deploy", "status", "scale"],
                       default="deploy", help="Action to perform")
    parser.add_argument("--replicas", type=int, help="Number of replicas for scaling")
    
    args = parser.parse_args()
    
    # Initialize orchestrator
    orchestrator = ProductionOrchestrator(args.config)
    
    environment = DeploymentEnvironment(args.environment)
    
    if args.action == "deploy":
        if args.service:
            # Deploy specific service
            result = await orchestrator.deploy_service(args.service, environment, args.strategy)
            print(f"Deployment result: {result.status.value}")
        else:
            # Deploy all services
            results = await orchestrator.deploy_all_services(environment, args.strategy)
            successful = len([r for r in results.values() if r.status == ServiceStatus.HEALTHY])
            print(f"Deployed {successful}/{len(results)} services successfully")
    
    elif args.action == "status":
        status = orchestrator.get_deployment_status()
        print(json.dumps(status, indent=2))
    
    elif args.action == "scale":
        if not args.service or not args.replicas:
            print("Service name and replicas required for scaling")
            return
        
        success = await orchestrator.scale_service(args.service, environment, args.replicas)
        print(f"Scaling {'successful' if success else 'failed'}")


if __name__ == "__main__":
    asyncio.run(main())